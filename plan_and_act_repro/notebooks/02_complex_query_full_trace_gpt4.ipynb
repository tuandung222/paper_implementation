{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e1fdf9",
   "metadata": {},
   "source": [
    "# Complex Query Full-Trace Monitoring with GPT-4\n",
    "\n",
    "Navigation links:\n",
    "- [Reading guide](../READING_GUIDE.md)\n",
    "- [Project README](../README.md)\n",
    "- [Architecture guide](../AGENT_FRAMEWORK_ARCHITECTURE.md)\n",
    "- [Tracing plan](../TRAINING_DATA_TRACING_PLAN.md)\n",
    "\n",
    "This notebook is built for **full observability**:\n",
    "1. Run a complex query that requires planning.\n",
    "2. Inspect full LLM input/output (system prompt, user prompt, raw response, parsed JSON, latency).\n",
    "3. Inspect full agent loop timeline and saved trace artifacts (`session.json`, `events.jsonl`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e42072",
   "metadata": {},
   "source": [
    "## 1) Setup and Environment Checks\n",
    "\n",
    "Requirements:\n",
    "- `.env` with `OPENAI_API_KEY`\n",
    "- Internet connection for real tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afecfe8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:07:02.152854Z",
     "iopub.status.busy": "2026-02-19T09:07:02.152497Z",
     "iopub.status.idle": "2026-02-19T09:07:02.169648Z",
     "shell.execute_reply": "2026-02-19T09:07:02.169239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/admin/TuanDung/paper_implementation/plan_and_act_repro\n",
      "OPENAI_API_KEY detected: True\n",
      "OPENAI_MODEL: gpt-4\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "cwd = Path.cwd().resolve()\n",
    "PROJECT_ROOT = cwd if (cwd / \"src\").exists() else cwd.parent\n",
    "if not (PROJECT_ROOT / \"src\").exists():\n",
    "    raise RuntimeError(\"Could not locate project root with src/ directory\")\n",
    "\n",
    "if str(PROJECT_ROOT / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "load_dotenv(PROJECT_ROOT / \".env\")\n",
    "\n",
    "API_KEY = (os.getenv(\"OPENAI_API_KEY\") or \"\").strip()\n",
    "MODEL_NAME = os.getenv(\"OPENAI_MODEL\", \"gpt-4\")\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"OPENAI_API_KEY detected:\", bool(API_KEY))\n",
    "print(\"OPENAI_MODEL:\", MODEL_NAME)\n",
    "\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY is required for this notebook.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dad93c",
   "metadata": {},
   "source": [
    "## 2) Build Instrumented LLM Client\n",
    "\n",
    "This client logs all model calls with:\n",
    "- component name (`planner`, `executor`, `replanner`)\n",
    "- prompts\n",
    "- raw text response\n",
    "- parsed JSON output\n",
    "- latency and status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4387a80c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:07:02.171995Z",
     "iopub.status.busy": "2026-02-19T09:07:02.171780Z",
     "iopub.status.idle": "2026-02-19T09:07:02.526549Z",
     "shell.execute_reply": "2026-02-19T09:07:02.526271Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import BadRequestError, OpenAI\n",
    "\n",
    "\n",
    "class InstrumentedLLMClient:\n",
    "    def __init__(self, *, component: str, ledger: list[dict[str, Any]], api_key: str, base_url: str = \"\") -> None:\n",
    "        self.component = component\n",
    "        self.ledger = ledger\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url.strip()\n",
    "\n",
    "    @property\n",
    "    def enabled(self) -> bool:\n",
    "        return bool(self.api_key)\n",
    "\n",
    "    def _client(self) -> OpenAI:\n",
    "        kwargs: dict[str, Any] = {\"api_key\": self.api_key}\n",
    "        if self.base_url:\n",
    "            kwargs[\"base_url\"] = self.base_url\n",
    "        return OpenAI(**kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_json_content(content: str) -> dict[str, Any]:\n",
    "        try:\n",
    "            return json.loads(content)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "        fenced = re.search(r\"```(?:json)?\\s*(\\{.*\\})\\s*```\", content, flags=re.DOTALL | re.IGNORECASE)\n",
    "        if fenced:\n",
    "            return json.loads(fenced.group(1))\n",
    "\n",
    "        start = content.find(\"{\")\n",
    "        end = content.rfind(\"}\")\n",
    "        if start != -1 and end != -1 and end > start:\n",
    "            return json.loads(content[start : end + 1])\n",
    "\n",
    "        raise ValueError(\"Model output is not valid JSON\")\n",
    "\n",
    "    def _repair_json(self, *, model: str, raw_text: str) -> tuple[str, dict[str, Any]]:\n",
    "        fixer_system = \"You convert malformed model output into strict JSON. Return JSON only.\"\n",
    "        fixer_user = (\n",
    "            \"Repair this into a valid JSON object with no markdown and no explanation.\\n\"\n",
    "            f\"RAW:\\n{raw_text}\"\n",
    "        )\n",
    "        resp = self._client().chat.completions.create(\n",
    "            model=model,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": fixer_system},\n",
    "                {\"role\": \"user\", \"content\": fixer_user},\n",
    "            ],\n",
    "        )\n",
    "        repaired_raw = resp.choices[0].message.content or \"{}\"\n",
    "        parsed = self._parse_json_content(repaired_raw)\n",
    "        return repaired_raw, parsed\n",
    "\n",
    "    def chat_json(\n",
    "        self,\n",
    "        *,\n",
    "        model: str,\n",
    "        system_prompt: str,\n",
    "        user_prompt: str,\n",
    "        temperature: float,\n",
    "    ) -> dict[str, Any]:\n",
    "        if not self.enabled:\n",
    "            raise RuntimeError(\"OPENAI_API_KEY is not set\")\n",
    "\n",
    "        started = time.perf_counter()\n",
    "        status = \"ok\"\n",
    "        raw_response = \"\"\n",
    "        parsed: dict[str, Any] | None = None\n",
    "        error_message = \"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            client = self._client()\n",
    "            try:\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    temperature=temperature,\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                    messages=messages,\n",
    "                )\n",
    "                raw_response = resp.choices[0].message.content or \"{}\"\n",
    "            except BadRequestError as exc:\n",
    "                if \"response_format\" not in str(exc):\n",
    "                    raise\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    temperature=temperature,\n",
    "                    messages=messages,\n",
    "                )\n",
    "                raw_response = resp.choices[0].message.content or \"{}\"\n",
    "\n",
    "            try:\n",
    "                parsed = self._parse_json_content(raw_response)\n",
    "            except Exception:\n",
    "                repaired_raw, repaired_parsed = self._repair_json(model=model, raw_text=raw_response)\n",
    "                raw_response = repaired_raw\n",
    "                parsed = repaired_parsed\n",
    "\n",
    "        except Exception as exc:\n",
    "            status = \"error\"\n",
    "            error_message = f\"{type(exc).__name__}: {exc}\"\n",
    "\n",
    "        latency_ms = round((time.perf_counter() - started) * 1000, 2)\n",
    "\n",
    "        self.ledger.append(\n",
    "            {\n",
    "                \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "                \"component\": self.component,\n",
    "                \"model\": model,\n",
    "                \"temperature\": temperature,\n",
    "                \"status\": status,\n",
    "                \"latency_ms\": latency_ms,\n",
    "                \"system_prompt\": system_prompt,\n",
    "                \"user_prompt\": user_prompt,\n",
    "                \"raw_response\": raw_response,\n",
    "                \"parsed_output\": parsed,\n",
    "                \"error\": error_message,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if status != \"ok\" or parsed is None:\n",
    "            raise RuntimeError(error_message or \"Unknown LLM error\")\n",
    "\n",
    "        return parsed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6490b8",
   "metadata": {},
   "source": [
    "## 3) Initialize Agents, Environment, and Tracer\n",
    "\n",
    "- GPT-4 primary agents\n",
    "- Heuristic fallbacks for notebook stability\n",
    "- Tool environment for real actions\n",
    "- Trace collector for full event timeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a93f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:07:02.527858Z",
     "iopub.status.busy": "2026-02-19T09:07:02.527773Z",
     "iopub.status.idle": "2026-02-19T09:07:02.565528Z",
     "shell.execute_reply": "2026-02-19T09:07:02.565315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace run id: nbtrace_20260219T093108Z\n",
      "Environment: tool_calling\n"
     ]
    }
   ],
   "source": [
    "from plan_and_act.agents.executor import ExecutorAgent\n",
    "from plan_and_act.agents.planner import PlannerAgent\n",
    "from plan_and_act.agents.replanner import ReplannerAgent\n",
    "from plan_and_act.core.schemas import PlanStep\n",
    "from plan_and_act.core.types import ModelConfig\n",
    "from plan_and_act.environments.factory import build_environment\n",
    "from plan_and_act.prompts.templates import PromptTemplates\n",
    "from plan_and_act.tracing import TraceCollector, TraceConfig\n",
    "\n",
    "llm_ledger: list[dict[str, Any]] = []\n",
    "\n",
    "prompts = PromptTemplates(config_dir=str(PROJECT_ROOT / \"configs\" / \"prompts\"))\n",
    "openai_cfg = ModelConfig(provider=\"openai\", model=MODEL_NAME, temperature=0.0)\n",
    "heur_cfg = ModelConfig(provider=\"heuristic\", model=MODEL_NAME, temperature=0.0)\n",
    "\n",
    "planner = PlannerAgent(openai_cfg, prompts)\n",
    "executor = ExecutorAgent(openai_cfg, prompts)\n",
    "replanner = ReplannerAgent(openai_cfg, prompts)\n",
    "\n",
    "planner_fallback = PlannerAgent(heur_cfg, prompts)\n",
    "executor_fallback = ExecutorAgent(heur_cfg, prompts)\n",
    "replanner_fallback = ReplannerAgent(heur_cfg, prompts)\n",
    "\n",
    "planner.llm = InstrumentedLLMClient(component=\"planner\", ledger=llm_ledger, api_key=API_KEY)\n",
    "executor.llm = InstrumentedLLMClient(component=\"executor\", ledger=llm_ledger, api_key=API_KEY)\n",
    "replanner.llm = InstrumentedLLMClient(component=\"replanner\", ledger=llm_ledger, api_key=API_KEY)\n",
    "\n",
    "env = build_environment(\"tool\")\n",
    "\n",
    "trace_run_id = \"nbtrace_\" + datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "trace_cfg = TraceConfig(enabled=True, base_dir=str(PROJECT_ROOT / \"data\" / \"raw\" / \"traces\"), flush_every=1)\n",
    "tracer = TraceCollector(config=trace_cfg, run_id=trace_run_id)\n",
    "\n",
    "print(\"Trace run id:\", trace_run_id)\n",
    "print(\"Environment:\", env.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36d65f5",
   "metadata": {},
   "source": [
    "## 4) Run Complex Planning Loop with Full Monitoring\n",
    "\n",
    "Complex query:\n",
    "- multi-step web research\n",
    "- comparison\n",
    "- weighted scoring\n",
    "- final recommendation with evidence URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad7bda4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:07:02.566672Z",
     "iopub.status.busy": "2026-02-19T09:07:02.566574Z",
     "iopub.status.idle": "2026-02-19T09:08:12.080554Z",
     "shell.execute_reply": "2026-02-19T09:08:12.080013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'goal': 'Research 3 recent long-horizon LLM agent approaches related to Plan-and-Act, compare them on novelty, reproducibility, and open-source readiness, then compute weighted score = 0.5*novelty + 0.3*reproducibility + 0.2*oss_readiness for each, and recommend the top approach with evidence URLs.',\n",
       " 'iterations': [{'step': 1,\n",
       "   'plan_step': {'step_id': 1,\n",
       "    'intent': \"Use 'web_search' tool to find recent long-horizon LLM agent approaches related to Plan-and-Act.\",\n",
       "    'success_criteria': '3 recent long-horizon LLM agent approaches have been found.'},\n",
       "   'action': {'action_type': 'search',\n",
       "    'target': 'web_search',\n",
       "    'arguments': {'query': 'recent long-horizon LLM agent approaches related to Plan-and-Act'},\n",
       "    'rationale': 'To find the recent long-horizon LLM agent approaches related to Plan-and-Act, a web search is necessary.',\n",
       "    'is_final': False,\n",
       "    'final_answer': ''},\n",
       "   'observation_after': 'Step 1: Tool[web_search] returned: {\"ok\": true, \"query\": \"recent long-horizon LLM agent approaches related to Plan-and-Act\", \"count\": 5, \"results\": [{\"title\": \"Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks\", \"url\": \"https://arxiv.org/abs/2503.09572\"}, {\"title\": \"The agentic \\\\\"long-horizon\\\\\" agent future - by dp\", \"url\": \"https://businesstechnologyvalue.substack.com/p/the-agentic-long-horizon-agent-future\"}, {\"title\": \"Our paper has been accepted by ICML. - Matsuo-Iwasawa Laboratory, The ...\", \"url\": \"https://weblab.t.u-tokyo.ac.jp/en/news/20250502/\"}, {\"title\": \"LLM-planning - 2025-03-13 - lxl-sword.github.io\", \"url\": \"https://lxl-sword.github.io/arxiv_paper_LLM_list/arxiv_LLM-planning_2025-03-13.html\"}, {\"title\": \"Plan-and-Act: Enhancing LLM Planning\", \"url\": \"https://www.emergentmind.com/papers/2503.09572\"}]}',\n",
       "   'done': False,\n",
       "   'success': False},\n",
       "  {'step': 2,\n",
       "   'plan_step': {'step_id': 1,\n",
       "    'intent': \"Use 'web_search' tool to find recent long-horizon LLM agent approaches related to Plan-and-Act.\",\n",
       "    'success_criteria': '3 recent long-horizon LLM agent approaches have been found.'},\n",
       "   'action': {'action_type': 'click',\n",
       "    'target': 'https://arxiv.org/abs/2503.09572',\n",
       "    'arguments': {},\n",
       "    'rationale': \"This link seems to lead to a paper titled 'Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks', which could be a recent long-horizon LLM agent approach related to Plan-and-Act.\",\n",
       "    'is_final': False,\n",
       "    'final_answer': ''},\n",
       "   'observation_after': 'Step 2: Tool[web_search] returned: {\"ok\": false, \"error\": \"Missing query\"}',\n",
       "   'done': False,\n",
       "   'success': False},\n",
       "  {'step': 3,\n",
       "   'plan_step': {'step_id': 1,\n",
       "    'intent': \"Use 'web_search' tool to find recent long-horizon LLM agent approaches related to Plan-and-Act.\",\n",
       "    'success_criteria': '3 recent long-horizon LLM agent approaches have been found.'},\n",
       "   'action': {'action_type': 'search',\n",
       "    'target': 'web_search',\n",
       "    'arguments': {'query': 'recent long-horizon LLM agent approaches related to Plan-and-Act'},\n",
       "    'rationale': 'To find the recent long-horizon LLM agent approaches related to Plan-and-Act, we need to perform a web search with the appropriate query.',\n",
       "    'is_final': False,\n",
       "    'final_answer': ''},\n",
       "   'observation_after': 'Step 3: Tool[web_search] returned: {\"ok\": true, \"query\": \"recent long-horizon LLM agent approaches related to Plan-and-Act\", \"count\": 5, \"results\": [{\"title\": \"Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks\", \"url\": \"https://arxiv.org/abs/2503.09572\"}, {\"title\": \"The agentic \\\\\"long-horizon\\\\\" agent future - by dp\", \"url\": \"https://businesstechnologyvalue.substack.com/p/the-agentic-long-horizon-agent-future\"}, {\"title\": \"Our paper has been accepted by ICML. - Matsuo-Iwasawa Laboratory, The ...\", \"url\": \"https://weblab.t.u-tokyo.ac.jp/en/news/20250502/\"}, {\"title\": \"LLM-planning - 2025-03-13 - lxl-sword.github.io\", \"url\": \"https://lxl-sword.github.io/arxiv_paper_LLM_list/arxiv_LLM-planning_2025-03-13.html\"}, {\"title\": \"Plan-and-Act: Enhancing LLM Planning\", \"url\": \"https://www.emergentmind.com/papers/2503.09572\"}]}',\n",
       "   'done': False,\n",
       "   'success': False},\n",
       "  {'step': 4,\n",
       "   'plan_step': {'step_id': 1,\n",
       "    'intent': \"Use 'web_search' tool to find recent long-horizon LLM agent approaches related to Plan-and-Act.\",\n",
       "    'success_criteria': '3 recent long-horizon LLM agent approaches have been found.'},\n",
       "   'action': {'action_type': 'click',\n",
       "    'target': 'https://arxiv.org/abs/2503.09572',\n",
       "    'arguments': {},\n",
       "    'rationale': \"This link seems to lead to a paper titled 'Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks', which could be one of the recent long-horizon LLM agent approaches related to Plan-and-Act.\",\n",
       "    'is_final': False,\n",
       "    'final_answer': ''},\n",
       "   'observation_after': 'Step 4: Tool[web_search] returned: {\"ok\": false, \"error\": \"Missing query\"}',\n",
       "   'done': False,\n",
       "   'success': False}],\n",
       " 'fallbacks': [],\n",
       " 'success': False,\n",
       " 'final_answer': '',\n",
       " 'trace_run_id': 'nbtrace_20260219T093108Z',\n",
       " 'llm_call_count': 9}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_goal = (\n",
    "    \"Research 3 recent long-horizon LLM agent approaches related to Plan-and-Act, \"\n",
    "    \"compare them on novelty, reproducibility, and open-source readiness, then compute \"\n",
    "    \"weighted score = 0.5*novelty + 0.3*reproducibility + 0.2*oss_readiness for each, \"\n",
    "    \"and recommend the top approach with evidence URLs.\"\n",
    ")\n",
    "\n",
    "runtime_summary: dict[str, Any] = {\n",
    "    \"goal\": complex_goal,\n",
    "    \"iterations\": [],\n",
    "    \"fallbacks\": [],\n",
    "}\n",
    "\n",
    "tracer.start_session(\n",
    "    goal=complex_goal,\n",
    "    environment={\"kind\": \"tool\", \"name\": env.name},\n",
    "    model_stack={\n",
    "        \"planner\": openai_cfg.model_dump(),\n",
    "        \"executor\": openai_cfg.model_dump(),\n",
    "        \"replanner\": openai_cfg.model_dump(),\n",
    "    },\n",
    "    runtime_config={\"max_iters\": 4, \"dynamic_replanning\": True},\n",
    "    metadata={\"source\": \"notebook\"},\n",
    ")\n",
    "\n",
    "observation = env.reset(goal=complex_goal)\n",
    "action_history: list[dict[str, Any]] = []\n",
    "max_iters = 4\n",
    "step_count = 0\n",
    "success = False\n",
    "final_answer = \"\"\n",
    "\n",
    "\n",
    "def call_with_fallback(label: str, primary_fn, fallback_fn):\n",
    "    try:\n",
    "        out = primary_fn()\n",
    "        return out, False, \"\"\n",
    "    except Exception as exc:\n",
    "        fb = fallback_fn()\n",
    "        return fb, True, f\"{label} failed: {type(exc).__name__}: {exc}\"\n",
    "\n",
    "\n",
    "# Initial planning\n",
    "tracer.log_event(event_type=\"planner_input\", step=step_count, payload={\"goal\": complex_goal, \"observation\": observation})\n",
    "plan, used_fb, fb_reason = call_with_fallback(\n",
    "    \"planner\",\n",
    "    lambda: planner.plan(goal=complex_goal, observation=observation, action_history=action_history, use_cot=False),\n",
    "    lambda: planner_fallback.plan(goal=complex_goal, observation=observation, action_history=action_history, use_cot=False),\n",
    ")\n",
    "if used_fb:\n",
    "    runtime_summary[\"fallbacks\"].append(fb_reason)\n",
    "tracer.log_event(event_type=\"planner_output\", step=step_count, payload={\"steps\": [s.model_dump() for s in plan.steps], \"fallback\": used_fb})\n",
    "\n",
    "for _ in range(max_iters):\n",
    "    if not plan.steps:\n",
    "        break\n",
    "\n",
    "    step_count += 1\n",
    "    current_step = plan.steps[0]\n",
    "\n",
    "    tracer.log_event(\n",
    "        event_type=\"executor_input\",\n",
    "        step=step_count,\n",
    "        payload={\n",
    "            \"current_step\": current_step.model_dump(),\n",
    "            \"observation\": observation,\n",
    "            \"action_history_length\": len(action_history),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    action, used_fb_exec, fb_reason_exec = call_with_fallback(\n",
    "        \"executor\",\n",
    "        lambda: executor.act(\n",
    "            goal=complex_goal,\n",
    "            current_step=current_step,\n",
    "            observation=observation,\n",
    "            step_index=0,\n",
    "            total_steps=max(1, len(plan.steps)),\n",
    "            use_cot=False,\n",
    "        ),\n",
    "        lambda: executor_fallback.act(\n",
    "            goal=complex_goal,\n",
    "            current_step=current_step,\n",
    "            observation=observation,\n",
    "            step_index=0,\n",
    "            total_steps=max(1, len(plan.steps)),\n",
    "            use_cot=False,\n",
    "        ),\n",
    "    )\n",
    "    if used_fb_exec:\n",
    "        runtime_summary[\"fallbacks\"].append(fb_reason_exec)\n",
    "\n",
    "    tracer.log_event(event_type=\"executor_output\", step=step_count, payload={\"action\": action.model_dump(), \"fallback\": used_fb_exec})\n",
    "\n",
    "    env_result = env.step(action=action, step_count=step_count)\n",
    "    tracer.log_event(\n",
    "        event_type=\"environment_step\",\n",
    "        step=step_count,\n",
    "        payload={\n",
    "            \"observation\": env_result.observation,\n",
    "            \"done\": env_result.done,\n",
    "            \"success\": env_result.success,\n",
    "            \"final_answer\": env_result.final_answer,\n",
    "            \"notes\": env_result.notes,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    action_history.append(action.model_dump())\n",
    "    runtime_summary[\"iterations\"].append(\n",
    "        {\n",
    "            \"step\": step_count,\n",
    "            \"plan_step\": current_step.model_dump(),\n",
    "            \"action\": action.model_dump(),\n",
    "            \"observation_after\": env_result.observation,\n",
    "            \"done\": env_result.done,\n",
    "            \"success\": env_result.success,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if action.is_final or env_result.done:\n",
    "        success = bool(action.is_final or env_result.success)\n",
    "        final_answer = action.final_answer or env_result.final_answer\n",
    "        break\n",
    "\n",
    "    observation = env_result.observation\n",
    "\n",
    "    tracer.log_event(\n",
    "        event_type=\"replanner_input\",\n",
    "        step=step_count,\n",
    "        payload={\n",
    "            \"previous_plan\": [s.model_dump() for s in plan.steps],\n",
    "            \"action_history_length\": len(action_history),\n",
    "            \"observation\": observation,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    plan, used_fb_rep, fb_reason_rep = call_with_fallback(\n",
    "        \"replanner\",\n",
    "        lambda: replanner.replan(\n",
    "            goal=complex_goal,\n",
    "            previous_plan=[s.model_dump() for s in plan.steps],\n",
    "            action_history=action_history,\n",
    "            observation=observation,\n",
    "            use_cot=False,\n",
    "        ),\n",
    "        lambda: replanner_fallback.replan(\n",
    "            goal=complex_goal,\n",
    "            previous_plan=[s.model_dump() for s in plan.steps],\n",
    "            action_history=action_history,\n",
    "            observation=observation,\n",
    "            use_cot=False,\n",
    "        ),\n",
    "    )\n",
    "    if used_fb_rep:\n",
    "        runtime_summary[\"fallbacks\"].append(fb_reason_rep)\n",
    "\n",
    "    tracer.log_event(event_type=\"replanner_output\", step=step_count, payload={\"steps\": [s.model_dump() for s in plan.steps], \"fallback\": used_fb_rep})\n",
    "\n",
    "runtime_summary[\"success\"] = success\n",
    "runtime_summary[\"final_answer\"] = final_answer\n",
    "runtime_summary[\"trace_run_id\"] = trace_run_id\n",
    "runtime_summary[\"llm_call_count\"] = len(llm_ledger)\n",
    "\n",
    "tracer.log_event(\n",
    "    event_type=\"episode_end\",\n",
    "    step=step_count,\n",
    "    payload={\n",
    "        \"success\": success,\n",
    "        \"final_answer\": final_answer,\n",
    "        \"fallback_count\": len(runtime_summary[\"fallbacks\"]),\n",
    "    },\n",
    ")\n",
    "tracer.close(\n",
    "    status=\"completed\",\n",
    "    summary={\n",
    "        \"success\": success,\n",
    "        \"step_count\": step_count,\n",
    "        \"llm_call_count\": len(llm_ledger),\n",
    "        \"fallback_count\": len(runtime_summary[\"fallbacks\"]),\n",
    "    },\n",
    ")\n",
    "\n",
    "runtime_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cab1d6c",
   "metadata": {},
   "source": [
    "## 5) Inspect Full LLM I/O Ledger\n",
    "\n",
    "You can inspect every LLM call in detail, including prompts and raw outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ab161d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:08:12.082910Z",
     "iopub.status.busy": "2026-02-19T09:08:12.082738Z",
     "iopub.status.idle": "2026-02-19T09:08:12.606096Z",
     "shell.execute_reply": "2026-02-19T09:08:12.605888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "call_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "component",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "latency_ms",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "bfedd4a5-86b5-464b-b515-79df7632fa29",
       "rows": [
        [
         "0",
         "0",
         "planner",
         "gpt-4",
         "ok",
         "9303.75"
        ],
        [
         "1",
         "1",
         "executor",
         "gpt-4",
         "ok",
         "3148.64"
        ],
        [
         "2",
         "2",
         "replanner",
         "gpt-4",
         "ok",
         "16809.05"
        ],
        [
         "3",
         "3",
         "executor",
         "gpt-4",
         "ok",
         "6442.72"
        ],
        [
         "4",
         "4",
         "replanner",
         "gpt-4",
         "ok",
         "19106.61"
        ],
        [
         "5",
         "5",
         "executor",
         "gpt-4",
         "ok",
         "4375.88"
        ],
        [
         "6",
         "6",
         "replanner",
         "gpt-4",
         "ok",
         "13949.85"
        ],
        [
         "7",
         "7",
         "executor",
         "gpt-4",
         "ok",
         "3689.89"
        ],
        [
         "8",
         "8",
         "replanner",
         "gpt-4",
         "ok",
         "19917.88"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_index</th>\n",
       "      <th>component</th>\n",
       "      <th>model</th>\n",
       "      <th>status</th>\n",
       "      <th>latency_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>planner</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>ok</td>\n",
       "      <td>9303.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>executor</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>ok</td>\n",
       "      <td>3148.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>replanner</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>ok</td>\n",
       "      <td>16809.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>executor</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>ok</td>\n",
       "      <td>6442.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>replanner</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>ok</td>\n",
       "      <td>19106.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>executor</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>ok</td>\n",
       "      <td>4375.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>replanner</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>ok</td>\n",
       "      <td>13949.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>executor</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>ok</td>\n",
       "      <td>3689.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>replanner</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>ok</td>\n",
       "      <td>19917.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   call_index  component  model status  latency_ms\n",
       "0           0    planner  gpt-4     ok     9303.75\n",
       "1           1   executor  gpt-4     ok     3148.64\n",
       "2           2  replanner  gpt-4     ok    16809.05\n",
       "3           3   executor  gpt-4     ok     6442.72\n",
       "4           4  replanner  gpt-4     ok    19106.61\n",
       "5           5   executor  gpt-4     ok     4375.88\n",
       "6           6  replanner  gpt-4     ok    13949.85\n",
       "7           7   executor  gpt-4     ok     3689.89\n",
       "8           8  replanner  gpt-4     ok    19917.88"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== CALL 0 | planner | status=ok =====\n",
      "\n",
      "--- SYSTEM PROMPT ---\n",
      "\n",
      "You are the Planner. Convert user goals into concise, executable, high-level steps.\n",
      "Return strictly valid JSON following the provided schema.\n",
      "\n",
      "Output JSON schema: {\"goal\": str, \"steps\": [{\"step_id\": int, \"intent\": str, \"success_criteria\": str}]}\n",
      "\n",
      "--- USER PROMPT ---\n",
      "\n",
      "Goal: Research 3 recent long-horizon LLM agent approaches related to Plan-and-Act, compare them on novelty, reproducibility, and open-source readiness, then compute weighted score = 0.5*novelty + 0.3*reproducibility + 0.2*oss_readiness for each, and recommend the top approach with evidence URLs.\n",
      "Observation: Tool environment initialized for goal: Research 3 recent long-horizon LLM agent approaches related to Plan-and-Act, compare them on novelty, reproducibility, and open-source readiness, then compute weighted score = 0.5*novelty + 0.3*reproducibility + 0.2*oss_readiness for each, and recommend the top approach with evidence URLs.. Registered tools=['calculator', 'fetch_url', 'github_top_contributor', 'web_search']\n",
      "Previous actions: []\n",
      "\n",
      "\n",
      "--- RAW RESPONSE ---\n",
      "\n",
      "{\"goal\": \"Research 3 recent long-horizon LLM agent approaches related to Plan-and-Act, compare them on novelty, reproducibility, and open-source readiness, then compute weighted score = 0.5*novelty + 0.3*reproducibility + 0.2*oss_readiness for each, and recommend the top approach with evidence URLs.\", \"steps\": [{\"step_id\": 1, \"intent\": \"Use 'web_search' tool to find recent long-horizon LLM agent approaches related to Plan-and-Act.\", \"success_criteria\": \"3 recent long-horizon LLM agent approaches have been found.\"}, {\"step_id\": 2, \"intent\": \"Use 'fetch_url' tool to gather information about each approach.\", \"success_criteria\": \"Information about each approach has been gathered.\"}, {\"step_id\": 3, \"intent\": \"Evaluate each approach on novelty, reproducibility, and open-source readiness.\", \"success_criteria\": \"Each approach has been evaluated on novelty, reproducibility, and open-source readiness.\"}, {\"step_id\": 4, \"intent\": \"Use 'calculator' tool to compute weighted score for each approach.\", \"success_criteria\": \"Weighted score for each approach has been computed.\"}, {\"step_id\": 5, \"intent\": \"Compare the weighted scores and recommend the top approach.\", \"success_criteria\": \"The top approach has been recommended with evidence URLs.\"}]}\n",
      "\n",
      "--- PARSED OUTPUT ---\n",
      "\n",
      "{\n",
      "  \"goal\": \"Research 3 recent long-horizon LLM agent approaches related to Plan-and-Act, compare them on novelty, reproducibility, and open-source readiness, then compute weighted score = 0.5*novelty + 0.3*reproducibility + 0.2*oss_readiness for each, and recommend the top approach with evidence URLs.\",\n",
      "  \"steps\": [\n",
      "    {\n",
      "      \"step_id\": 1,\n",
      "      \"intent\": \"Use 'web_search' tool to find recent long-horizon LLM agent approaches related to Plan-and-Act.\",\n",
      "      \"success_criteria\": \"3 recent long-horizon LLM agent approaches have been found.\"\n",
      "    },\n",
      "    {\n",
      "      \"step_id\": 2,\n",
      "      \"intent\": \"Use 'fetch_url' tool to gather information about each approach.\",\n",
      "      \"success_criteria\": \"Information about each approach has been gathered.\"\n",
      "    },\n",
      "    {\n",
      "      \"step_id\": 3,\n",
      "      \"intent\": \"Evaluate each approach on novelty, reproducibility, and open-source readiness.\",\n",
      "      \"success_criteria\": \"Each approach has been evaluated on novelty, reproducibility, and open-source readiness.\"\n",
      "    },\n",
      "    {\n",
      "      \"step_id\": 4,\n",
      "      \"intent\": \"Use 'calculator' tool to compute weighted score for each approach.\",\n",
      "      \"success_criteria\": \"Weighted score for each approach has been computed.\"\n",
      "    },\n",
      "    {\n",
      "      \"step_id\": 5,\n",
      "      \"intent\": \"Compare the weighted scores and recommend the top approach.\",\n",
      "      \"success_criteria\": \"The top approach has been recommended with evidence URLs.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "ledger_df = pd.DataFrame(llm_ledger)\n",
    "if ledger_df.empty:\n",
    "    print(\"No LLM calls captured.\")\n",
    "else:\n",
    "    display(\n",
    "        ledger_df[[\"component\", \"model\", \"status\", \"latency_ms\"]]\n",
    "        .assign(call_index=lambda d: d.index)\n",
    "        [[\"call_index\", \"component\", \"model\", \"status\", \"latency_ms\"]]\n",
    "    )\n",
    "\n",
    "\n",
    "def show_call(call_index: int) -> None:\n",
    "    row = llm_ledger[call_index]\n",
    "    print(f\"===== CALL {call_index} | {row['component']} | status={row['status']} =====\")\n",
    "    print(\"\\n--- SYSTEM PROMPT ---\\n\")\n",
    "    print(row[\"system_prompt\"])\n",
    "    print(\"\\n--- USER PROMPT ---\\n\")\n",
    "    print(row[\"user_prompt\"])\n",
    "    print(\"\\n--- RAW RESPONSE ---\\n\")\n",
    "    print(row[\"raw_response\"])\n",
    "    print(\"\\n--- PARSED OUTPUT ---\\n\")\n",
    "    print(json.dumps(row[\"parsed_output\"], indent=2, ensure_ascii=False) if row[\"parsed_output\"] else None)\n",
    "    if row.get(\"error\"):\n",
    "        print(\"\\n--- ERROR ---\\n\")\n",
    "        print(row[\"error\"])\n",
    "\n",
    "\n",
    "# Inspect first call by default\n",
    "if llm_ledger:\n",
    "    show_call(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969bba0",
   "metadata": {},
   "source": [
    "## 6) Inspect Full Runtime Timeline from Trace Files\n",
    "\n",
    "This section reads `session.json` and `events.jsonl` generated in this notebook run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66a7b301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T09:08:12.607753Z",
     "iopub.status.busy": "2026-02-19T09:08:12.607548Z",
     "iopub.status.idle": "2026-02-19T09:08:12.616939Z",
     "shell.execute_reply": "2026-02-19T09:08:12.616701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace directory: /Users/admin/TuanDung/paper_implementation/plan_and_act_repro/data/raw/traces/nbtrace_20260219T093108Z\n",
      "session exists: True\n",
      "events exists: True\n",
      "\n",
      "Session summary:\n",
      "{\n",
      "  \"success\": false,\n",
      "  \"step_count\": 4,\n",
      "  \"llm_call_count\": 9,\n",
      "  \"fallback_count\": 0,\n",
      "  \"event_count\": 23\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "step",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "event_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "3cf14422-de70-4c31-bb0c-da644b6287c0",
       "rows": [
        [
         "0",
         "0",
         "planner_input",
         "2026-02-19T09:31:09.940815+00:00"
        ],
        [
         "1",
         "0",
         "planner_output",
         "2026-02-19T09:31:19.245508+00:00"
        ],
        [
         "2",
         "1",
         "executor_input",
         "2026-02-19T09:31:19.247593+00:00"
        ],
        [
         "3",
         "1",
         "executor_output",
         "2026-02-19T09:31:22.404951+00:00"
        ],
        [
         "4",
         "1",
         "environment_step",
         "2026-02-19T09:31:24.026406+00:00"
        ],
        [
         "5",
         "1",
         "replanner_input",
         "2026-02-19T09:31:24.027726+00:00"
        ],
        [
         "6",
         "1",
         "replanner_output",
         "2026-02-19T09:31:40.847826+00:00"
        ],
        [
         "7",
         "2",
         "executor_input",
         "2026-02-19T09:31:40.849111+00:00"
        ],
        [
         "8",
         "2",
         "executor_output",
         "2026-02-19T09:31:47.306045+00:00"
        ],
        [
         "9",
         "2",
         "environment_step",
         "2026-02-19T09:31:47.320600+00:00"
        ],
        [
         "10",
         "2",
         "replanner_input",
         "2026-02-19T09:31:47.330665+00:00"
        ],
        [
         "11",
         "2",
         "replanner_output",
         "2026-02-19T09:32:06.446107+00:00"
        ],
        [
         "12",
         "3",
         "executor_input",
         "2026-02-19T09:32:06.451630+00:00"
        ],
        [
         "13",
         "3",
         "executor_output",
         "2026-02-19T09:32:10.831141+00:00"
        ],
        [
         "14",
         "3",
         "environment_step",
         "2026-02-19T09:32:12.222915+00:00"
        ],
        [
         "15",
         "3",
         "replanner_input",
         "2026-02-19T09:32:12.223807+00:00"
        ],
        [
         "16",
         "3",
         "replanner_output",
         "2026-02-19T09:32:26.184172+00:00"
        ],
        [
         "17",
         "4",
         "executor_input",
         "2026-02-19T09:32:26.194498+00:00"
        ],
        [
         "18",
         "4",
         "executor_output",
         "2026-02-19T09:32:29.892921+00:00"
        ],
        [
         "19",
         "4",
         "environment_step",
         "2026-02-19T09:32:29.903822+00:00"
        ],
        [
         "20",
         "4",
         "replanner_input",
         "2026-02-19T09:32:29.913077+00:00"
        ],
        [
         "21",
         "4",
         "replanner_output",
         "2026-02-19T09:32:49.839333+00:00"
        ],
        [
         "22",
         "4",
         "episode_end",
         "2026-02-19T09:32:49.849758+00:00"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 23
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>event_type</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>planner_input</td>\n",
       "      <td>2026-02-19T09:31:09.940815+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>planner_output</td>\n",
       "      <td>2026-02-19T09:31:19.245508+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>executor_input</td>\n",
       "      <td>2026-02-19T09:31:19.247593+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>executor_output</td>\n",
       "      <td>2026-02-19T09:31:22.404951+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>environment_step</td>\n",
       "      <td>2026-02-19T09:31:24.026406+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>replanner_input</td>\n",
       "      <td>2026-02-19T09:31:24.027726+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>replanner_output</td>\n",
       "      <td>2026-02-19T09:31:40.847826+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>executor_input</td>\n",
       "      <td>2026-02-19T09:31:40.849111+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>executor_output</td>\n",
       "      <td>2026-02-19T09:31:47.306045+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>environment_step</td>\n",
       "      <td>2026-02-19T09:31:47.320600+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>replanner_input</td>\n",
       "      <td>2026-02-19T09:31:47.330665+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>replanner_output</td>\n",
       "      <td>2026-02-19T09:32:06.446107+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>executor_input</td>\n",
       "      <td>2026-02-19T09:32:06.451630+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>executor_output</td>\n",
       "      <td>2026-02-19T09:32:10.831141+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>environment_step</td>\n",
       "      <td>2026-02-19T09:32:12.222915+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>replanner_input</td>\n",
       "      <td>2026-02-19T09:32:12.223807+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>replanner_output</td>\n",
       "      <td>2026-02-19T09:32:26.184172+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>executor_input</td>\n",
       "      <td>2026-02-19T09:32:26.194498+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>executor_output</td>\n",
       "      <td>2026-02-19T09:32:29.892921+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>environment_step</td>\n",
       "      <td>2026-02-19T09:32:29.903822+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>replanner_input</td>\n",
       "      <td>2026-02-19T09:32:29.913077+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>replanner_output</td>\n",
       "      <td>2026-02-19T09:32:49.839333+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>episode_end</td>\n",
       "      <td>2026-02-19T09:32:49.849758+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    step        event_type                         timestamp\n",
       "0      0     planner_input  2026-02-19T09:31:09.940815+00:00\n",
       "1      0    planner_output  2026-02-19T09:31:19.245508+00:00\n",
       "2      1    executor_input  2026-02-19T09:31:19.247593+00:00\n",
       "3      1   executor_output  2026-02-19T09:31:22.404951+00:00\n",
       "4      1  environment_step  2026-02-19T09:31:24.026406+00:00\n",
       "5      1   replanner_input  2026-02-19T09:31:24.027726+00:00\n",
       "6      1  replanner_output  2026-02-19T09:31:40.847826+00:00\n",
       "7      2    executor_input  2026-02-19T09:31:40.849111+00:00\n",
       "8      2   executor_output  2026-02-19T09:31:47.306045+00:00\n",
       "9      2  environment_step  2026-02-19T09:31:47.320600+00:00\n",
       "10     2   replanner_input  2026-02-19T09:31:47.330665+00:00\n",
       "11     2  replanner_output  2026-02-19T09:32:06.446107+00:00\n",
       "12     3    executor_input  2026-02-19T09:32:06.451630+00:00\n",
       "13     3   executor_output  2026-02-19T09:32:10.831141+00:00\n",
       "14     3  environment_step  2026-02-19T09:32:12.222915+00:00\n",
       "15     3   replanner_input  2026-02-19T09:32:12.223807+00:00\n",
       "16     3  replanner_output  2026-02-19T09:32:26.184172+00:00\n",
       "17     4    executor_input  2026-02-19T09:32:26.194498+00:00\n",
       "18     4   executor_output  2026-02-19T09:32:29.892921+00:00\n",
       "19     4  environment_step  2026-02-19T09:32:29.903822+00:00\n",
       "20     4   replanner_input  2026-02-19T09:32:29.913077+00:00\n",
       "21     4  replanner_output  2026-02-19T09:32:49.839333+00:00\n",
       "22     4       episode_end  2026-02-19T09:32:49.849758+00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 2 events:\n",
      "{\n",
      "  \"run_id\": \"nbtrace_20260219T093108Z\",\n",
      "  \"step\": 4,\n",
      "  \"event_type\": \"replanner_output\",\n",
      "  \"timestamp\": \"2026-02-19T09:32:49.839333+00:00\",\n",
      "  \"payload\": {\n",
      "    \"steps\": [\n",
      "      {\n",
      "        \"step_id\": 1,\n",
      "        \"intent\": \"Use 'web_search' tool to find recent long-horizon LLM agent approaches related to Plan-and-Act.\",\n",
      "        \"success_criteria\": \"3 recent long-horizon LLM agent approaches have been found.\"\n",
      "      },\n",
      "      {\n",
      "        \"step_id\": 2,\n",
      "        \"intent\": \"Use 'fetch_url' tool to gather information about the first approach from the search results.\",\n",
      "        \"success_criteria\": \"Information about the first approach has been gathered.\"\n",
      "      },\n",
      "      {\n",
      "        \"step_id\": 3,\n",
      "        \"intent\": \"Use 'web_search' tool to find the second recent long-horizon LLM agent approach related to Plan-and-Act.\",\n",
      "        \"success_criteria\": \"Second recent long-horizon LLM agent approach has been found.\"\n",
      "      },\n",
      "      {\n",
      "        \"step_id\": 4,\n",
      "        \"intent\": \"Use 'fetch_url' tool to gather information about the second approach from the search results.\",\n",
      "        \"success_criteria\": \"Information about the second approach has been gathered.\"\n",
      "      },\n",
      "      {\n",
      "        \"step_id\": 5,\n",
      "        \"intent\": \"Use 'web_search' tool to find the third recent long-horizon LLM agent approach related to Plan-and-Act.\",\n",
      "        \"success_criteria\": \"Third recent long-horizon LLM agent approach has been found.\"\n",
      "      },\n",
      "      {\n",
      "        \"step_id\": 6,\n",
      "        \"intent\": \"Use 'fetch_url' tool to gather information about the third approach from the search results.\",\n",
      "        \"success_criteria\": \"Information about the third approach has been gathered.\"\n",
      "      },\n",
      "      {\n",
      "        \"step_id\": 7,\n",
      "        \"intent\": \"Evaluate each approach on novelty, reproducibility, and open-source readiness.\",\n",
      "        \"success_criteria\": \"Each approach has been evaluated on novelty, reproducibility, and open-source readiness.\"\n",
      "      },\n",
      "      {\n",
      "        \"step_id\": 8,\n",
      "        \"intent\": \"Use 'calculator' tool to compute weighted score for each approach.\",\n",
      "        \"success_criteria\": \"Weighted score for each approach has been computed.\"\n",
      "      },\n",
      "      {\n",
      "        \"step_id\": 9,\n",
      "        \"intent\": \"Compare the weighted scores and recommend the top approach.\",\n",
      "        \"success_criteria\": \"The top approach has been recommended with evidence URLs.\"\n",
      "      }\n",
      "    ],\n",
      "    \"fallback\": false\n",
      "  },\n",
      "  \"meta\": {}\n",
      "}\n",
      "{\n",
      "  \"run_id\": \"nbtrace_20260219T093108Z\",\n",
      "  \"step\": 4,\n",
      "  \"event_type\": \"episode_end\",\n",
      "  \"timestamp\": \"2026-02-19T09:32:49.849758+00:00\",\n",
      "  \"payload\": {\n",
      "    \"success\": false,\n",
      "    \"final_answer\": \"\",\n",
      "    \"fallback_count\": 0\n",
      "  },\n",
      "  \"meta\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "trace_dir = PROJECT_ROOT / \"data\" / \"raw\" / \"traces\" / trace_run_id\n",
    "session_path = trace_dir / \"session.json\"\n",
    "events_path = trace_dir / \"events.jsonl\"\n",
    "\n",
    "print(\"Trace directory:\", trace_dir)\n",
    "print(\"session exists:\", session_path.exists())\n",
    "print(\"events exists:\", events_path.exists())\n",
    "\n",
    "session = json.loads(session_path.read_text(encoding=\"utf-8\"))\n",
    "print(\"\\nSession summary:\")\n",
    "print(json.dumps(session.get(\"summary\", {}), indent=2))\n",
    "\n",
    "events = []\n",
    "for line in events_path.read_text(encoding=\"utf-8\").splitlines():\n",
    "    line = line.strip()\n",
    "    if line:\n",
    "        events.append(json.loads(line))\n",
    "\n",
    "events_df = pd.DataFrame(events)\n",
    "display(events_df[[\"step\", \"event_type\", \"timestamp\"]])\n",
    "\n",
    "print(\"\\nLast 2 events:\")\n",
    "for ev in events[-2:]:\n",
    "    print(json.dumps(ev, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076343f3",
   "metadata": {},
   "source": [
    "## 7) Notes\n",
    "\n",
    "- This notebook is intended for **full observability**, not minimal token usage.\n",
    "- For repeatable runs, keep `OPENAI_MODEL` fixed and do not change prompt templates during comparison.\n",
    "- You can copy this notebook pattern for other agent papers by replacing only:\n",
    "  1. query/task\n",
    "  2. toolset\n",
    "  3. planner/executor/replanner prompt templates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a423ea",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
