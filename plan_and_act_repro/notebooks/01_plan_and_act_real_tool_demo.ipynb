{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Tutorial: Plan-and-Act Module Inspection and Real Tool Demo\n\nAudience:\n- AI Researchers\n- Data Scientists\n- Agent Architects / Agent Scientists\n\nPrerequisites:\n- Python 3.11+\n- Environment installed from this repo (`pip install -e .[dev]`)\n- Optional: `OPENAI_API_KEY` in `.env` to run GPT-4 path\n\nLearning goals:\n1. Import and inspect each core module in the scaffold.\n2. Understand Planner/Executor/Replanner interfaces.\n3. Run a complete local workflow episode.\n4. Run a real tool-integrated example using GitHub API.\n\nNavigation links:\n- [Reading guide](../READING_GUIDE.md)\n- [Project README](../README.md)\n- [Reproduction plan](../REPRODUCTION_PLAN.md)\n- [Paper review](../PLAN_AND_ACT_review.md)\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Outline\n\n1. Setup and imports\n2. Inspect core modules (`types`, `schemas`, `state`)\n3. Inspect agent modules (`planner`, `executor`, `replanner`, `judge`)\n4. Inspect and run graph workflow (`workflow`, `transitions`)\n5. Real tool demo: GitHub API integration\n6. Tool-augmented mini Plan-and-Act episode\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from __future__ import annotations\n\nimport inspect\nimport importlib\nimport os\nimport sys\nfrom pathlib import Path\n\nfrom dotenv import load_dotenv\n\n# Resolve project root no matter where this notebook is launched from.\ncwd = Path.cwd().resolve()\nPROJECT_ROOT = cwd if (cwd / \"src\").exists() else cwd.parent\nif not (PROJECT_ROOT / \"src\").exists():\n    raise RuntimeError(\"Could not locate project root with src/ directory\")\n\nif str(PROJECT_ROOT / \"src\") not in sys.path:\n    sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n\nload_dotenv(PROJECT_ROOT / \".env\")\n\nprint(\"Project root:\", PROJECT_ROOT)\nprint(\"OPENAI_API_KEY detected:\", bool(os.getenv(\"OPENAI_API_KEY\", \"\").strip()))\nprint(\"OPENAI_MODEL:\", os.getenv(\"OPENAI_MODEL\", \"(default in config)\"))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 1 - Inspect Core Modules\n\nWe inspect `plan_and_act.core` to understand the data contracts that keep the system clean and testable.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "core_modules = [\n    \"plan_and_act.core.types\",\n    \"plan_and_act.core.schemas\",\n    \"plan_and_act.core.state\",\n]\n\nfor module_name in core_modules:\n    mod = importlib.import_module(module_name)\n    print(f\"\\n=== {module_name} ===\")\n    symbols = [n for n in dir(mod) if not n.startswith(\"_\")]\n    print(\"symbols:\", symbols)\n\nfrom plan_and_act.core.schemas import PlanStep, PlannerOutput, ExecutorAction\nfrom plan_and_act.core.state import build_initial_state\n\nprint(\"\\nPlanStep signature:\", inspect.signature(PlanStep))\nprint(\"PlannerOutput fields:\", PlannerOutput.model_fields.keys())\nprint(\"ExecutorAction fields:\", ExecutorAction.model_fields.keys())\n\nexample_state = build_initial_state(\n    goal=\"Find top contributor of a GitHub repo\",\n    max_steps=5,\n    dynamic_replanning=True,\n    use_cot=False,\n)\nprint(\"\\nInitial state keys:\", sorted(example_state.keys()))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 2 - Inspect Agent Modules\n\nNow we inspect each agent class and run a small heuristic pass.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from plan_and_act.core.types import ModelConfig\nfrom plan_and_act.prompts.templates import PromptTemplates\nfrom plan_and_act.agents.planner import PlannerAgent\nfrom plan_and_act.agents.executor import ExecutorAgent\nfrom plan_and_act.agents.replanner import ReplannerAgent\nfrom plan_and_act.agents.judge import JudgeAgent\nfrom plan_and_act.core.schemas import PlanStep\n\nprompts = PromptTemplates(config_dir=str(PROJECT_ROOT / \"configs\" / \"prompts\"))\n\n# Use OpenAI path when key exists, else deterministic heuristic path.\nprovider = \"openai\" if os.getenv(\"OPENAI_API_KEY\", \"\").strip() else \"heuristic\"\nmcfg = ModelConfig(provider=provider, model=os.getenv(\"OPENAI_MODEL\", \"gpt-4\"), temperature=0.0)\n\nplanner = PlannerAgent(mcfg, prompts)\nexecutor = ExecutorAgent(mcfg, prompts)\nreplanner = ReplannerAgent(mcfg, prompts)\njudge = JudgeAgent()\n\nprint(\"PlannerAgent.plan signature:\", inspect.signature(planner.plan))\nprint(\"ExecutorAgent.act signature:\", inspect.signature(executor.act))\nprint(\"ReplannerAgent.replan signature:\", inspect.signature(replanner.replan))\n\nplan = planner.plan(\n    goal=\"Find the top contributor and return profile link\",\n    observation=\"Tooling available: GitHub API\",\n    action_history=[],\n    use_cot=False,\n)\nprint(\"\\nPlanner output:\")\nprint(plan.model_dump())\n\naction = executor.act(\n    goal=plan.goal,\n    current_step=plan.steps[0] if plan.steps else PlanStep(step_id=1, intent=\"Fallback\", success_criteria=\"\"),\n    observation=\"No environment action has been executed yet.\",\n    step_index=0,\n    total_steps=max(len(plan.steps), 1),\n    use_cot=False,\n)\nprint(\"\\nExecutor output:\")\nprint(action.model_dump())\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 3 - Inspect and Run Graph Workflow\n\nThis executes the current LangGraph workflow (`Planner -> Executor -> Replanner`) with the local simulator adapter.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from plan_and_act.graph.workflow import build_workflow\nfrom plan_and_act.eval.metrics import compute_episode_metrics\n\nworkflow = build_workflow(planner, executor, replanner)\nstate = build_initial_state(\n    goal=\"Follow the top contributor of this GitHub project\",\n    max_steps=4,\n    dynamic_replanning=True,\n    use_cot=False,\n)\n\nfinal_state = workflow.invoke(state)\nmetrics = compute_episode_metrics(final_state)\n\nprint(\"Final state summary:\")\nprint({\n    \"success\": final_state[\"success\"],\n    \"step_count\": final_state[\"step_count\"],\n    \"final_answer\": final_state[\"final_answer\"],\n    \"replans\": sum(1 for n in final_state[\"notes\"] if \"Replanned\" in n),\n})\nprint(\"\\nMetrics:\", metrics)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 4 - Real Tool Demo (GitHub API)\n\nBelow is a **real external tool** call. We query GitHub REST API to fetch the top contributor of a real repository.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import json\nimport urllib.request\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass GitHubTool:\n    base_url: str = \"https://api.github.com\"\n\n    def _get(self, path: str) -> dict | list:\n        req = urllib.request.Request(\n            url=f\"{self.base_url}{path}\",\n            headers={\"User-Agent\": \"plan-and-act-repro-demo\"},\n            method=\"GET\",\n        )\n        with urllib.request.urlopen(req, timeout=20) as resp:\n            payload = resp.read().decode(\"utf-8\")\n        return json.loads(payload)\n\n    def top_contributor(self, owner: str, repo: str) -> dict:\n        data = self._get(f\"/repos/{owner}/{repo}/contributors?per_page=1\")\n        if not data:\n            return {\"found\": False, \"reason\": \"No contributors returned\"}\n        top = data[0]\n        return {\n            \"found\": True,\n            \"owner\": owner,\n            \"repo\": repo,\n            \"login\": top.get(\"login\", \"\"),\n            \"contributions\": top.get(\"contributions\", 0),\n            \"profile_url\": top.get(\"html_url\", \"\"),\n        }\n\n\ngh_tool = GitHubTool()\nresult = gh_tool.top_contributor(\"openai\", \"openai-python\")\nresult\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 5 - Tool-Augmented Mini Episode\n\nWe combine planner + real tool observation + replanner/executor to simulate a realistic planning loop.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "goal = \"Find the top contributor of openai/openai-python and provide profile URL\"\n\ninitial_plan = planner.plan(\n    goal=goal,\n    observation=\"Tool available: GitHub REST API contributor endpoint\",\n    action_history=[],\n    use_cot=False,\n)\n\ntool_observation = (\n    f\"Top contributor for openai/openai-python: {result.get('login')} \"\n    f\"with {result.get('contributions')} contributions, profile={result.get('profile_url')}\"\n)\n\nupdated_plan = replanner.replan(\n    goal=goal,\n    previous_plan=[s.model_dump() for s in initial_plan.steps],\n    action_history=[{\"tool\": \"github_api\", \"observation\": result}],\n    observation=tool_observation,\n    use_cot=False,\n)\n\n# Ask executor to produce one final action based on the replanned context.\nfinal_step = updated_plan.steps[0] if updated_plan.steps else PlanStep(step_id=1, intent=\"Return final answer\", success_criteria=\"\")\nfinal_action = executor.act(\n    goal=goal,\n    current_step=final_step,\n    observation=tool_observation,\n    step_index=0,\n    total_steps=1,\n    use_cot=False,\n)\n\nsummary = {\n    \"goal\": goal,\n    \"initial_plan_steps\": [s.intent for s in initial_plan.steps],\n    \"tool_result\": result,\n    \"updated_plan_steps\": [s.intent for s in updated_plan.steps],\n    \"final_action\": final_action.model_dump(),\n}\nsummary\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Next Steps\n\n1. Replace `GitHubTool` with browser tools (Playwright/WebArena adapters).\n2. Attach run logging for each notebook episode into `artifacts/runs/`.\n3. Compare heuristic vs GPT-4 mode on identical goals and collect metrics.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}