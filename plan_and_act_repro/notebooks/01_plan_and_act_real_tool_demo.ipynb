{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# GPT-4 Real Demo: Plan-and-Act + Real Tools\n\nNavigation links:\n- [Reading guide](../READING_GUIDE.md)\n- [Project README](../README.md)\n- [Reproduction plan](../REPRODUCTION_PLAN.md)\n- [Architecture guide](../AGENT_FRAMEWORK_ARCHITECTURE.md)\n- [Paper review](../PLAN_AND_ACT_review.md)\n\nThis notebook demonstrates:\n1. Real GPT-4 calls through Planner/Executor/Replanner.\n2. Real tools without model API key (`web_search`, `fetch_url`, `calculator`).\n3. One end-to-end episode on the generic `tool` environment.\n",
      "id": "0ed88115"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Setup\n\n- Load project root and `.env`.\n- Verify `OPENAI_API_KEY` exists for GPT-4 cells.\n- Add `src/` to `sys.path` for local imports.\n",
      "id": "7cba53c8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from __future__ import annotations\n\nimport os\nimport sys\nfrom pathlib import Path\nfrom dotenv import load_dotenv\n\ncwd = Path.cwd().resolve()\nPROJECT_ROOT = cwd if (cwd / \"src\").exists() else cwd.parent\nif not (PROJECT_ROOT / \"src\").exists():\n    raise RuntimeError(\"Could not locate project root with src/ directory\")\n\nif str(PROJECT_ROOT / \"src\") not in sys.path:\n    sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n\nload_dotenv(PROJECT_ROOT / \".env\")\n\nHAS_KEY = bool((os.getenv(\"OPENAI_API_KEY\") or \"\").strip())\nMODEL_NAME = os.getenv(\"OPENAI_MODEL\", \"gpt-4\")\n\nprint(\"Project root:\", PROJECT_ROOT)\nprint(\"OPENAI_API_KEY detected:\", HAS_KEY)\nprint(\"OPENAI_MODEL:\", MODEL_NAME)\n\nif not HAS_KEY:\n    raise RuntimeError(\"OPENAI_API_KEY is required for this GPT-4 demo notebook.\")\n",
      "id": "a94c008d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2) Inspect Core Modules and Interfaces\n\nQuick inspection of schemas and signatures before running the real demo.\n",
      "id": "101a4f8b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import inspect\nimport importlib\n\ncore_modules = [\n    \"plan_and_act.core.types\",\n    \"plan_and_act.core.schemas\",\n    \"plan_and_act.core.state\",\n    \"plan_and_act.environments.base\",\n    \"plan_and_act.tools.base\",\n]\n\nfor module_name in core_modules:\n    mod = importlib.import_module(module_name)\n    print(f\"\\n=== {module_name} ===\")\n    symbols = [n for n in dir(mod) if not n.startswith(\"_\")]\n    print(\"symbols:\", symbols)\n\nfrom plan_and_act.core.schemas import PlanStep\nfrom plan_and_act.agents.planner import PlannerAgent\nfrom plan_and_act.agents.executor import ExecutorAgent\nfrom plan_and_act.agents.replanner import ReplannerAgent\n\nprint(\"\\nPlannerAgent.plan:\", inspect.signature(PlannerAgent.plan))\nprint(\"ExecutorAgent.act:\", inspect.signature(ExecutorAgent.act))\nprint(\"ReplannerAgent.replan:\", inspect.signature(ReplannerAgent.replan))\nprint(\"PlanStep fields:\", PlanStep.model_fields.keys())\n",
      "id": "f5344ee5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3) Real GPT-4 Planner/Executor/Replanner Calls\n\nThis cell uses GPT-4 for all three agents.\n",
      "id": "09d59623"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from plan_and_act.core.types import ModelConfig\nfrom plan_and_act.prompts.templates import PromptTemplates\n\nprompts = PromptTemplates(config_dir=str(PROJECT_ROOT / \"configs\" / \"prompts\"))\nopenai_cfg = ModelConfig(provider=\"openai\", model=MODEL_NAME, temperature=0.0)\n\nplanner = PlannerAgent(openai_cfg, prompts)\nexecutor = ExecutorAgent(openai_cfg, prompts)\nreplanner = ReplannerAgent(openai_cfg, prompts)\n\ngoal = \"Find the top contributor of openai/openai-python and return their profile URL\"\n\n\ndef safe_call(name: str, fn):\n    try:\n        return {\"ok\": True, \"value\": fn()}\n    except Exception as exc:\n        return {\"ok\": False, \"error\": f\"{type(exc).__name__}: {exc}\"}\n\nplanner_res = safe_call(\n    \"planner\",\n    lambda: planner.plan(\n        goal=goal,\n        observation=\"Tool environment with web_search, fetch_url, calculator, github_top_contributor\",\n        action_history=[],\n        use_cot=False,\n    ),\n)\n\nif planner_res[\"ok\"] and planner_res[\"value\"].steps:\n    first_step = planner_res[\"value\"].steps[0]\nelse:\n    first_step = PlanStep(step_id=1, intent=\"Search top contributor\", success_criteria=\"Contributor identified\")\n\nexecutor_res = safe_call(\n    \"executor\",\n    lambda: executor.act(\n        goal=goal,\n        current_step=first_step,\n        observation=\"No action executed yet.\",\n        step_index=0,\n        total_steps=max(1, len(planner_res[\"value\"].steps) if planner_res[\"ok\"] else 1),\n        use_cot=False,\n    ),\n)\n\nreplanner_res = safe_call(\n    \"replanner\",\n    lambda: replanner.replan(\n        goal=goal,\n        previous_plan=[s.model_dump() for s in planner_res[\"value\"].steps] if planner_res[\"ok\"] else [],\n        action_history=[executor_res[\"value\"].model_dump()] if executor_res[\"ok\"] else [],\n        observation=\"Tool result: top contributor is known.\",\n        use_cot=False,\n    ),\n)\n\n{\n    \"planner\": planner_res[\"value\"].model_dump() if planner_res[\"ok\"] else planner_res,\n    \"executor\": executor_res[\"value\"].model_dump() if executor_res[\"ok\"] else executor_res,\n    \"replanner\": replanner_res[\"value\"].model_dump() if replanner_res[\"ok\"] else replanner_res,\n}\n",
      "id": "3f654cb5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Real Built-in Tools Demo (No Model Key Needed)\n\nThese tool calls do not use model API keys.\n",
      "id": "e5bc0eef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from plan_and_act.tools.factory import build_default_tool_registry\n\nregistry = build_default_tool_registry()\n\nsearch_out = registry.call(\"web_search\", {\"query\": \"plan and act llm agents\", \"max_results\": 3})\nfetch_out = registry.call(\"fetch_url\", {\"url\": \"https://arxiv.org/abs/2503.09572v3\", \"max_chars\": 400})\ncalc_out = registry.call(\"calculator\", {\"expression\": \"(42 * 13) / 7 + sqrt(81)\"})\ngh_out = registry.call(\"github_top_contributor\", {\"owner\": \"openai\", \"repo\": \"openai-python\"})\n\n{\n    \"search_ok\": search_out.get(\"ok\"),\n    \"search_count\": search_out.get(\"count\"),\n    \"fetch_ok\": fetch_out.get(\"ok\"),\n    \"fetch_title\": fetch_out.get(\"title\"),\n    \"calc_out\": calc_out,\n    \"github_out\": gh_out,\n}\n",
      "id": "38169c5a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) End-to-End Episode on Generic Tool Environment (Deterministic Runtime)\n\nTo keep notebook execution stable across runs, this end-to-end loop uses deterministic agents.\nGPT-4 real calls were already validated in Step 3.\n",
      "id": "d30263bc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from plan_and_act.core.state import build_initial_state\nfrom plan_and_act.core.types import ModelConfig\nfrom plan_and_act.environments.factory import build_environment\nfrom plan_and_act.eval.metrics import compute_episode_metrics\nfrom plan_and_act.graph.workflow import build_workflow\n\n# Deterministic loop for robust notebook execution.\nheuristic_cfg = ModelConfig(provider=\"heuristic\", model=MODEL_NAME, temperature=0.0)\nplanner_loop = PlannerAgent(heuristic_cfg, prompts)\nexecutor_loop = ExecutorAgent(heuristic_cfg, prompts)\nreplanner_loop = ReplannerAgent(heuristic_cfg, prompts)\n\nenv = build_environment(\"tool\")\nworkflow = build_workflow(planner_loop, executor_loop, replanner_loop, env)\n\ninitial_state = build_initial_state(\n    goal=goal,\n    max_steps=4,\n    dynamic_replanning=True,\n    use_cot=False,\n    observation=env.reset(goal=goal),\n)\n\nfinal_state = workflow.invoke(initial_state)\nmetrics = compute_episode_metrics(final_state)\n\n{\n    \"success\": final_state.get(\"success\"),\n    \"step_count\": final_state.get(\"step_count\"),\n    \"final_answer\": final_state.get(\"final_answer\"),\n    \"latest_observation\": final_state.get(\"observation\"),\n    \"metrics\": metrics,\n}\n",
      "id": "03ae7b61"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6) Notes\n\n- This notebook is designed for real execution with GPT-4 and real tools.\n- For CI/offline checks, you can run unit tests and the no-key tool demo script:\n  - `pytest -q`\n  - `./scripts/run_real_tools_demo.sh`\n",
      "id": "7779440b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}